{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of tabular data to other formats for querying \n",
    "The purpose of this notebook is to test (memory, time) efficient methods to work with big data that don't fit into memory for queries and to run downstream analyses. In this case the data are large tabular files of mobile data. \n",
    "The two methods I will try are: \n",
    "\n",
    "1) To create a database [with SQLite](https://www.sqlite.org/index.html)\n",
    "2) To re-write the data to a parquet format using [Apache Arrow](https://arrow.apache.org/docs/python/parquet.html)\n",
    "\n",
    "(The second option honestly seems much faster and better than the first, at least so far in my hands.)\n",
    "\n",
    "other resources to look into: \n",
    "- [Apache Beam](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/sql_taxi.py)\n",
    "- [mobilekit POI mapping](https://mobilkit.readthedocs.io/en/latest/examples/M4R_03_POI_visit_analysis.html) and related [docs](https://mobilkit.readthedocs.io/en/latest/mobilkit.spatial.html)\n",
    "- [info](https://docs.dask.org/en/stable/generated/dask.dataframe.read_parquet.html) about reading parquet files with dask "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading and package imports shared across methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/year=2019/month=1/', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/year=2019/month=2/']\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import glob\n",
    "#from tqdm import tqdm, notebook\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import mobilkit #.loader.crop_spatial as mkcrop_spatial\n",
    "\n",
    "# Access environment variables and define other necessary variables\n",
    "data_dir = os.getenv('WORKING_DIR')\n",
    "meta_dir = f'{data_dir}metadata/'\n",
    "\n",
    "data_2019 = f'{data_dir}data/year=2019/'\n",
    "data_folders = glob.glob((data_2019 + '*/'))\n",
    "\n",
    "initial_cols=['device_id', 'id_type', 'latitude', 'longitude', 'horizontal_accuracy', 'timestamp',  'ip_address', 'device_os', 'country', 'unknown_2', 'geohash']\n",
    "sel_cols = [\"device_id\",\"latitude\",\"longitude\",\"timestamp\",\"geohash\",\"horizontal_accuracy\"]\n",
    "final_cols = [\"uid\",\"lat\",\"lng\",\"datetime\",\"geohash\",\"horizontal_accuracy\"]\n",
    "\n",
    "# boundary box that roughly captures the larger county of Bogota\n",
    "minlon = -74.453\n",
    "maxlon = -73.992\n",
    "minlat = 3.727\n",
    "maxlat = 4.835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FUNCTIONS FOR DATA PROCESSING ####\n",
    "\n",
    "def get_days(data_folder):\n",
    "    \"\"\"Assuming a directory organized as a month's worth of days with files in each directory like \"day=01\", etc \"\"\"\n",
    "    day_dirs = glob.glob((data_folder + '*/'))\n",
    "    return day_dirs\n",
    "\n",
    "def get_files(data_folder, day_dir):\n",
    "    \"\"\"Assuming a dir corresponding to and named for a day day_dir, (e.g. \"day=01\") within the data_folder with that day's mobile data files.\"\"\"\n",
    "    day = day_dir.split(data_folder)[1]\n",
    "    filepaths = glob.glob((day_dir + '*[!*.gz]')) # select all the non-zipped mobile data files\n",
    "    return filepaths, day\n",
    "\n",
    "def load_data(filepaths, initial_cols, sel_cols, final_cols): \n",
    "    \"\"\"Load in the mobile data and specify the columns\"\"\"\n",
    "    ddf = dd.read_csv(filepaths, names=initial_cols)\n",
    "    ddf = ddf[sel_cols]\n",
    "    ddf.columns = final_cols\n",
    "    return ddf \n",
    "\n",
    "def convert_datetime(ddf: dd.DataFrame): #needs work\n",
    "    \"\"\"Process timestamp to datetime for dataframe with a \"datatime\" column with timestamp values. \"\"\"\n",
    "    ddf[\"datetime\"] = dd.to_datetime(ddf[\"datetime\"], unit='ms', errors='coerce')\n",
    "    ddf[\"datetime\"] = ddf[\"datetime\"].dt.tz_localize('UTC').dt.tz_convert('America/Bogota')\n",
    "    return ddf\n",
    "\n",
    "def preprocess_mobile(ddf: dd.DataFrame, final_cols: list, minlon , maxlon, minlat, maxlat): #needs work\n",
    "    \"\"\"Select only those points within an area of interest and process timestamp to datetime \n",
    "    for dataframe with a \"datatime\" column with timestamp values.\"\"\"\n",
    "    ddf = find_within_box(ddf, minlon, maxlon, minlat, maxlat)\n",
    "    ddf = convert_datetime(ddf)[final_cols]\n",
    "    df = ddf.compute()\n",
    "    return df\n",
    "\n",
    "def find_within_box(ddf, minlon, maxlon, minlat, maxlat):\n",
    "    \"\"\"Quick way to filter out points not in a particular rectangular region.\"\"\"\n",
    "    box=[minlon,minlat,maxlon,maxlat]\n",
    "    filtered_ddf = mobilkit.loader.crop_spatial(ddf, box).reset_index()\n",
    "    return filtered_ddf\n",
    "\n",
    "#### FUNCTIONS FOR PARQUET CONVERSION ####\n",
    "\n",
    "def write_to_pq(df, out_dir, filename): \n",
    "    table_name = f'{out_dir}{filename}.parquet'\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, table_name)\n",
    "\n",
    "def from_month_write_filter_days_to_pq(data_folder: str, month: str, year: str, out_dir:str):\n",
    "    day_dirs = glob.glob((data_folder + '*/'))\n",
    "    for i in tqdm(range(0,len(day_dirs)), desc=f'Files from {year} {month} processed'): \n",
    "        day_dir = day_dirs[i]\n",
    "        filepaths, day = get_files(data_folder, day_dir)\n",
    "        day_name = day.split('/')[0]\n",
    "        ddf = load_data(filepaths, initial_cols, sel_cols, final_cols)\n",
    "        df = preprocess_mobile(ddf, final_cols, minlon, maxlon, minlat, maxlat)\n",
    "        filename = f'bogota_area_{year}_{month}_{day_name}'\n",
    "        write_to_pq(df, out_dir, filename)\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Re-formatting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert tabular data to parquet\n",
    "For each day in each month, load the files for the Colombia mobile data, filter the pings that are roughly in the Bogota area, and process the datetime. Write each day as a parquet file with the year, month, and day information in the filename.\n",
    "\n",
    "More information [here](https://arrow.apache.org/docs/python/parquet.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c19e3d08b564fd9ad9c664ec87baa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files from year=2019 month=1 processed:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f972fa89324363a8827c912d1a1320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files from year=2019 month=2 processed:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n",
      "/opt/anaconda3/envs/geo_mobile/lib/python3.9/site-packages/dask/core.py:119: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*(_execute_task(a, cache) for a in args))\n"
     ]
    }
   ],
   "source": [
    "in_dir = f'{data_dir}data/'\n",
    "year = 'year=2019'\n",
    "data_year = f'{in_dir}{year}/'\n",
    "data_folders = glob.glob((data_year + '*/'))\n",
    "\n",
    "out_dir = f'{data_dir}data/parquet/'\n",
    "\n",
    "for i in range(0, len(data_folders)):\n",
    "    data_folder = data_folders[i]\n",
    "    month = data_folder.split(data_year)[1].split('/')[0]\n",
    "    from_month_write_filter_days_to_pq(data_folder, month, year, out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset from parquet\n",
    "Convert the parquet files into a dataset that is queryable\n",
    "\n",
    "More information [here](https://arrow.apache.org/docs/python/dataset.html#dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "pq_dir = f'{data_dir}data/parquet/'\n",
    "#pq_dir = f'{data_dir}data/test_parquet/'\n",
    "\n",
    "dataset = ds.dataset(pq_dir, format=\"parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the documentation \"Creating a Dataset object does not begin reading the data itself. If needed, it only crawls the directory to find all the file and infers the dataset’s schema (by default from the first file).\" \n",
    "\n",
    "Lets look at some properties of the dataset, including what files it would be based on and some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=01.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=02.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=03.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=04.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=05.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=06.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=07.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=08.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=09.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=10.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=11.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=12.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=13.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=14.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=15.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=16.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=17.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=18.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=19.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=20.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=21.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=22.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=23.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=24.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=25.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=26.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=27.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=28.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=29.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=30.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=31.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=01.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=02.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=03.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=04.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=05.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=06.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=07.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=08.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=09.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=10.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=11.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=12.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=13.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=14.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=15.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=16.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=17.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=18.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=19.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=20.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=21.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=22.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=23.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=24.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=25.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=26.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=27.parquet', '/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=28.parquet']\n",
      "uid: string\n",
      "lat: double\n",
      "lng: double\n",
      "datetime: timestamp[us, tz=America/Bogota]\n",
      "geohash: string\n",
      "horizontal_accuracy: double\n",
      "__index_level_0__: int64\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [\"__index_level_0__\"], \"column_indexes\": [{\"na' + 1055\n",
      "[<pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=01.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=02.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=03.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=04.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=05.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=06.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=07.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=08.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=09.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=10.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=11.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=12.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=13.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=14.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=15.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=16.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=17.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=18.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=19.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=20.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=21.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=22.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=23.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=24.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=25.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=26.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=27.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=28.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=29.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=30.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=1_day=31.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=01.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=02.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=03.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=04.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=05.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=06.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=07.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=08.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=09.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=10.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=11.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=12.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=13.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=14.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=15.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=16.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=17.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=18.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=19.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=20.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=21.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=22.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=23.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=24.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=25.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=26.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=27.parquet>, <pyarrow.dataset.ParquetFileFragment path=/Users/emilyrobitschek/git/ETH/SPUR/mobile_data_colombia/data/parquet/bogota_area_year=2019_month=2_day=28.parquet>]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.files)\n",
    "print(dataset.schema.to_string(show_field_metadata=False))\n",
    "fragments = list(dataset.get_fragments())\n",
    "print(fragments)\n",
    "#fragments.split_by_row_group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Dataset.to_table() method we can read the dataset (or a portion of it) into a pyarrow Table. Depending on the dataset size this can require a lot of memory, so it's best to consider filtering the dataset first. For instance if we only want the user id column we can execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>min_day</th>\n",
       "      <th>max_day</th>\n",
       "      <th>pings</th>\n",
       "      <th>daysActive</th>\n",
       "      <th>daysSpanned</th>\n",
       "      <th>pingsPerDay</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004c9e3-5cba-42b9-93a1-9a0863cd727d</td>\n",
       "      <td>2019-01-05 00:00:00-05:00</td>\n",
       "      <td>2019-01-05 00:00:00-05:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[18]</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005e98f-60a8-4fee-aa37-3932aa9b9a09</td>\n",
       "      <td>2019-01-01 00:00:00-05:00</td>\n",
       "      <td>2019-01-24 00:00:00-05:00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>[7, 5, 2]</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00094aa7-3cff-43f2-a4ab-cf294178e973</td>\n",
       "      <td>2019-01-11 00:00:00-05:00</td>\n",
       "      <td>2019-01-30 00:00:00-05:00</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>[9, 1, 5, 25, 5, 6, 56, 1]</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e37e7-925a-4ab8-b456-1ba283c2de97</td>\n",
       "      <td>2018-12-31 00:00:00-05:00</td>\n",
       "      <td>2019-01-31 00:00:00-05:00</td>\n",
       "      <td>379</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 19, 16, 5, 1, 1, 242, 46, 9, 1, 38]</td>\n",
       "      <td>34.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000f520c-13ce-4e80-803a-801ea05933a8</td>\n",
       "      <td>2019-01-05 00:00:00-05:00</td>\n",
       "      <td>2019-01-29 00:00:00-05:00</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>[1, 1, 84, 3, 44]</td>\n",
       "      <td>26.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid                   min_day  \\\n",
       "0  0004c9e3-5cba-42b9-93a1-9a0863cd727d 2019-01-05 00:00:00-05:00   \n",
       "1  0005e98f-60a8-4fee-aa37-3932aa9b9a09 2019-01-01 00:00:00-05:00   \n",
       "2  00094aa7-3cff-43f2-a4ab-cf294178e973 2019-01-11 00:00:00-05:00   \n",
       "3  000e37e7-925a-4ab8-b456-1ba283c2de97 2018-12-31 00:00:00-05:00   \n",
       "4  000f520c-13ce-4e80-803a-801ea05933a8 2019-01-05 00:00:00-05:00   \n",
       "\n",
       "                    max_day  pings  daysActive  daysSpanned  \\\n",
       "0 2019-01-05 00:00:00-05:00     18           1            1   \n",
       "1 2019-01-24 00:00:00-05:00     14           3           23   \n",
       "2 2019-01-30 00:00:00-05:00    108           8           19   \n",
       "3 2019-01-31 00:00:00-05:00    379          11           31   \n",
       "4 2019-01-29 00:00:00-05:00    133           5           24   \n",
       "\n",
       "                               pingsPerDay        avg  \n",
       "0                                     [18]  18.000000  \n",
       "1                                [7, 5, 2]   4.666667  \n",
       "2               [9, 1, 5, 25, 5, 6, 56, 1]  13.500000  \n",
       "3  [1, 19, 16, 5, 1, 1, 242, 46, 9, 1, 38]  34.454545  \n",
       "4                        [1, 1, 84, 3, 44]  26.600000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_user_stats(dataset):\n",
    "    table = dataset.to_table(columns=['uid', 'datetime']).to_pandas()\n",
    "    table_dd = dd.from_pandas(table, npartitions=10)\n",
    "    user_stats = mobilkit.stats.userStats(table_dd).compute()\n",
    "    return user_stats\n",
    "\n",
    "user_stats = compute_user_stats(dataset)\n",
    "user_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 171381 users in the dataset, 15089 of which have more than 60 pings.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>npings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adb6de33-05cd-452d-b0fc-2d77450776e9</td>\n",
       "      <td>13592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c278355a-ca73-4093-9ac0-e22a1101307d</td>\n",
       "      <td>12839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4a9ac0b5-7157-48c6-85d9-ec411fcc1fe1</td>\n",
       "      <td>10105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7665a25-87d8-4741-8f74-d9d705ab4801</td>\n",
       "      <td>8174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78cef64c-8329-4834-a101-8e376db2faf4</td>\n",
       "      <td>7943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  npings\n",
       "0  adb6de33-05cd-452d-b0fc-2d77450776e9   13592\n",
       "1  c278355a-ca73-4093-9ac0-e22a1101307d   12839\n",
       "2  4a9ac0b5-7157-48c6-85d9-ec411fcc1fe1   10105\n",
       "3  b7665a25-87d8-4741-8f74-d9d705ab4801    8174\n",
       "4  78cef64c-8329-4834-a101-8e376db2faf4    7943"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_pings = 60\n",
    "user_stats = pd.DataFrame(table.uid.value_counts()).reset_index().rename({'index': 'uid', 'uid': 'npings'}, axis=1)\n",
    "user_stats_filtered = user_stats[user_stats['npings'] >= 60]\n",
    "print(f'There are {len(user_stats)} users in the dataset, {len(user_stats_filtered)} of which have more than {min_pings} pings.')\n",
    "user_stats_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_minpings = list(user_stats_filtered['uid'])\n",
    "table = dataset.to_table(filter=ds.field('uid').isin(uid_minpings)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter by particular queries, which is so cool! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1cc76e6dfe46bcbb0c4f0bfadb02f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>npings</th>\n",
       "      <th>daysActive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adb6de33-05cd-452d-b0fc-2d77450776e9</td>\n",
       "      <td>85339</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78cef64c-8329-4834-a101-8e376db2faf4</td>\n",
       "      <td>61060</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42149981-aa71-4323-a77a-2e174df5c4a9</td>\n",
       "      <td>55705</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3f52705d-f8b9-437b-aa15-790b5aaf407a</td>\n",
       "      <td>52943</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c278355a-ca73-4093-9ac0-e22a1101307d</td>\n",
       "      <td>40419</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  npings daysActive\n",
       "0  adb6de33-05cd-452d-b0fc-2d77450776e9   85339         31\n",
       "1  78cef64c-8329-4834-a101-8e376db2faf4   61060         30\n",
       "2  42149981-aa71-4323-a77a-2e174df5c4a9   55705         56\n",
       "3  3f52705d-f8b9-437b-aa15-790b5aaf407a   52943         27\n",
       "4  c278355a-ca73-4093-9ac0-e22a1101307d   40419         18"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_daysActive(dataset, uid): \n",
    "    table = dataset.to_table(filter=ds.field('uid') == uid).to_pandas()\n",
    "    table['day'] = table['datetime'].apply(lambda x: str(x).split(' ', 1)[0])\n",
    "    daysactive = table.nunique()['day']\n",
    "    return daysactive\n",
    "\n",
    "for i in trange(0, 10): #, desc=f'Users processed'): #len(user_stats_filtered))\n",
    "    if 'daysActive' not in list(user_stats_filtered.columns):\n",
    "        user_stats_filtered['daysActive'] = None\n",
    "    daysactive = calculate_daysActive(dataset, user_stats_filtered['uid'][i])\n",
    "    user_stats_filtered['daysActive'][i] = daysactive\n",
    "\n",
    "user_stats_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adb6de33-05cd-452d-b0fc-2d77450776e9'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stats_filtered['uid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>daysActive</th>\n",
       "      <th>npings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1fb81f41-7260-4fa1-b061-b4ed1e482984</td>\n",
       "      <td>51</td>\n",
       "      <td>8231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  daysActive  npings\n",
       "0  1fb81f41-7260-4fa1-b061-b4ed1e482984          51    8231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_daysActive(dataset, uid): \n",
    "    table = dataset.to_table(filter=ds.field('uid') == uid).to_pandas()\n",
    "    table['day'] = table['datetime'].apply(lambda x: str(x).split(' ', 1)[0])\n",
    "    daysactive = [table.nunique()['day']]\n",
    "    return table, daysactive\n",
    "\n",
    "uid = '1fb81f41-7260-4fa1-b061-b4ed1e482984'\n",
    "table = dataset.to_table(filter=ds.field('uid') == uid).to_pandas()\n",
    "table['day'] = [str(i).split(' ', 1)[0] for i in table['datetime']] #day_name returns day of the week \n",
    "\n",
    "user_stats = pd.DataFrame({})\n",
    "user_stats['uid'] = [uid]\n",
    "user_stats['daysActive'] = [table.nunique()['day']]\n",
    "user_stats['npings'] = [len(table)]\n",
    "\n",
    "user_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_dir = f'{data_dir}data/test_parquet/'\n",
    "ddf = dd.read_parquet(pq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>poilat</th>\n",
       "      <th>poilon</th>\n",
       "      <th>types</th>\n",
       "      <th>status</th>\n",
       "      <th>perm_closed</th>\n",
       "      <th>filename</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veterinaria Cani yi</td>\n",
       "      <td>4.7627</td>\n",
       "      <td>-74.0427</td>\n",
       "      <td>['veterinary_care', 'point_of_interest', 'esta...</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>False</td>\n",
       "      <td>vets</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veterinary Clinic La Salle University</td>\n",
       "      <td>4.7553</td>\n",
       "      <td>-74.0261</td>\n",
       "      <td>['hospital', 'veterinary_care', 'health', 'poi...</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>False</td>\n",
       "      <td>vets</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asistencia Médica Canina Cani Yi</td>\n",
       "      <td>4.7629</td>\n",
       "      <td>-74.0430</td>\n",
       "      <td>['veterinary_care', 'point_of_interest', 'esta...</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>False</td>\n",
       "      <td>vets</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pet Shop Pelos Huellas y Bigotes</td>\n",
       "      <td>4.7442</td>\n",
       "      <td>-74.0989</td>\n",
       "      <td>['veterinary_care', 'point_of_interest', 'esta...</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>False</td>\n",
       "      <td>vets</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guau guau .com</td>\n",
       "      <td>4.7493</td>\n",
       "      <td>-74.1106</td>\n",
       "      <td>['veterinary_care', 'point_of_interest', 'esta...</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>False</td>\n",
       "      <td>vets</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  poilat   poilon  \\\n",
       "0                    Veterinaria Cani yi  4.7627 -74.0427   \n",
       "1  Veterinary Clinic La Salle University  4.7553 -74.0261   \n",
       "2       Asistencia Médica Canina Cani Yi  4.7629 -74.0430   \n",
       "3       Pet Shop Pelos Huellas y Bigotes  4.7442 -74.0989   \n",
       "4                         guau guau .com  4.7493 -74.1106   \n",
       "\n",
       "                                               types       status perm_closed  \\\n",
       "0  ['veterinary_care', 'point_of_interest', 'esta...  OPERATIONAL       False   \n",
       "1  ['hospital', 'veterinary_care', 'health', 'poi...  OPERATIONAL       False   \n",
       "2  ['veterinary_care', 'point_of_interest', 'esta...  OPERATIONAL       False   \n",
       "3  ['veterinary_care', 'point_of_interest', 'esta...  OPERATIONAL       False   \n",
       "4  ['veterinary_care', 'point_of_interest', 'esta...  OPERATIONAL       False   \n",
       "\n",
       "  filename  radius  \n",
       "0     vets     0.1  \n",
       "1     vets     0.1  \n",
       "2     vets     0.1  \n",
       "3     vets     0.1  \n",
       "4     vets     0.1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poi_loc = pd.read_csv(f\"{meta_dir}/places/google_places.csv\")\n",
    "df_poi_loc = df_poi_loc.rename(columns={\"lat\": \"poilat\", \"lon\": \"poilon\"})\n",
    "df_poi_loc['radius'] = 0.1 #in kilometers\n",
    "df_poi_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('geo_mobile')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94266dc0016789288e396fdf5aae0a4b8003dfb3304fe52aa146b44e3e043f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
