{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and filter the data by day\n",
    "For each month of data, load the data for each day and filter it first with a box that includes a region around Bogota and then with a shapefile with regions relevant to the study area that we care about (e.g. neighbhorhoods within Bogota). Write out that data in an efficient format (parquet) for calculation of user stats and filtering by user stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "working_dir = os.getenv(\"WORKING_DIR\")\n",
    "os.environ[\"USE_PYGEOS\"] = \"0\"\n",
    "\n",
    "from setup import *\n",
    "from plotting import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = read_config(f\"{working_dir}configs/config_2018.yml\")\n",
    "(\n",
    "    year,\n",
    "    datatypes,\n",
    "    initial_cols,\n",
    "    sel_cols,\n",
    "    final_cols,\n",
    "    minlon,\n",
    "    maxlon,\n",
    "    minlat,\n",
    "    maxlat,\n",
    ") = get_config_vars(c=c, mode=\"preprocess\")\n",
    "min_days, min_pings = get_config_vars(c=c, mode=\"user_qc\")\n",
    "\n",
    "where = get_dirs(working_dir, year=year, min_days=min_days, min_pings=min_pings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the shapefile and plot it to see if it is what we might expect for the study areas we want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile, gdf_regions = get_shp(\n",
    "    meta_dir=where.meta_dir, shp_name=c[\"meta\"][\"shp\"][\"study_area\"], load=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and sanity checks: \n",
    "For one day, filter the points by region and check the plots to ensure that the filtering is working as expected before applying the function to the whole dataset. \n",
    "- Time to run: ~ 2 minutes, including plotting functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and plot a fraction of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one day for testing\n",
    "i = 0\n",
    "data_folder = where.data_folders[i]\n",
    "month = data_folder.split(where.data_year)[1].split(\"/\")[0]\n",
    "day_dirs = get_days(data_folder)\n",
    "day_dir = day_dirs[i]\n",
    "\n",
    "filepaths, day = get_files(data_folder, day_dir)\n",
    "day_name = day.split(\"/\")[0]\n",
    "ddf = load_data(\n",
    "    filepaths,\n",
    "    initial_cols=initial_cols,\n",
    "    sel_cols=sel_cols,\n",
    "    final_cols=final_cols,\n",
    "    datatypes=datatypes,\n",
    ")\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_obj, user_data = plot_frac_data_on_map(\n",
    "    shapefile_path=shapefile, ddf=ddf, frac=0.0001\n",
    ")\n",
    "map_obj.save(f\"{where.plot_dir}/{year}_{month}_{day_name}_user_pings_raw_f0001.html\")\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and plot a fraction of the data limited to a box around the area of Bogota\n",
    "This reduces the data size quite substantially and quickly (by a factor of ~3 or so depending on how much data is outside the roughly defined region around Bogota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_box_ddf = find_within_box(ddf, minlon, maxlon, minlat, maxlat)\n",
    "map_obj, user_data = plot_frac_data_on_map(\n",
    "    shapefile_path=shapefile, ddf=within_box_ddf, frac=0.0001\n",
    ")\n",
    "map_obj.save(f\"{where.plot_dir}/{year}_{month}_{day_name}_user_pings_bogbox_f0001.html\")\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and plot a fraction of the data limited to the regions within the area of Bogota that are designated by our shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_in_regions = find_within_regions(ddf, gdf=gdf_regions)\n",
    "map_obj, user_data = plot_frac_data_on_map(\n",
    "    shapefile_path=shapefile, ddf=ddf_in_regions, frac=0.01\n",
    ")\n",
    "map_obj.save(\n",
    "    f\"{where.plot_dir}/{year}_{month}_{day_name}_user_pings_in_studyareashp_f01.html\"\n",
    ")\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well. Let's make a function to more easily apply this filtering to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function testing for the one day:\n",
    "ddf_in_regions = filter_data_for_day(\n",
    "    filepaths,\n",
    "    gdf=gdf_regions,\n",
    "    initial_cols=initial_cols,\n",
    "    sel_cols=sel_cols,\n",
    "    final_cols=final_cols,\n",
    "    datatypes=datatypes,\n",
    "    minlon=minlon,\n",
    "    maxlon=maxlon,\n",
    "    minlat=minlat,\n",
    "    maxlat=maxlat,\n",
    ")\n",
    "ddf_in_regions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter all the days in the dataset for all months\n",
    "Because the previous functions appeared to filter the data in the desired way, we will now apply that filtering to the whole dataset\n",
    "- Time to run \n",
    "    - ~83 minutes (2019 data) ~44 minutes (2018 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_in_study_area(where: Where, config_path: str):\n",
    "    print(config_path)\n",
    "    c = read_config(path=config_path)\n",
    "    shapefile, gdf_regions = get_shp(\n",
    "        meta_dir=where.meta_dir, shp_name=c[\"meta\"][\"shp\"][\"study_area\"], load=True\n",
    "    )\n",
    "    (\n",
    "        year,\n",
    "        datatypes,\n",
    "        initial_cols,\n",
    "        sel_cols,\n",
    "        final_cols,\n",
    "        minlon,\n",
    "        maxlon,\n",
    "        minlat,\n",
    "        maxlat,\n",
    "    ) = get_config_vars(c=c, mode=\"preprocess\")\n",
    "    for i in range(0, len(where.data_folders)):\n",
    "        data_folder = where.data_folders[i]\n",
    "        from_month_write_filter_days_to_pq(\n",
    "            data_folder,\n",
    "            gdf=gdf_regions,\n",
    "            out_dir=where.study_area_dir,\n",
    "            data_year=where.data_year,\n",
    "            year=year,\n",
    "            initial_cols=initial_cols,\n",
    "            sel_cols=sel_cols,\n",
    "            final_cols=final_cols,\n",
    "            datatypes=datatypes,\n",
    "            minlon=minlon,\n",
    "            maxlon=maxlon,\n",
    "            minlat=minlat,\n",
    "            maxlat=maxlat,\n",
    "        )\n",
    "\n",
    "\n",
    "write_data_in_study_area(where, config_path=f\"{working_dir}configs/config_2018.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the user stats based on the pings from the study area regions\n",
    "May take quite some time. \n",
    "- Time to run ~115 minutes (2019 data) ~73 minutes (2018 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats = compute_user_stats_from_pq(where.study_area_dir)\n",
    "user_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out user stats for the whole dataset for filtering\n",
    "Based on 60 ping and 10 day mininum cutoffs, kept 701961 of a total of 3557494 users for this dataset (2019 data). Based on 60 ping and 10 day mininum cutoffs, kept 365261 of a total of 2637382 users for this dataset (2018 dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats = write_filter_user_stats(\n",
    "    user_stats, output_dir=where.user_stats_dir, year=year, filter_by_frequency=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats_filtered = write_filter_user_stats(\n",
    "    user_stats,\n",
    "    output_dir=where.user_stats_dir,\n",
    "    year=year,\n",
    "    filter_by_frequency=True,\n",
    "    min_pings=min_pings,\n",
    "    min_days=min_days,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset by users that pass quality control \n",
    "Write out to parquet file for downstream analysis. (Reorganized the files into folders with 1 month of data each, except the first three months that are smaller in size.) \n",
    "- Time to run: ~14 min (2019 data) ~ 3 min (2018 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = f\"{where.pass_qc_dir}user_stats_{year}_{min_pings}min_pings_{min_days}min_days_shp_filtered.csv\"\n",
    "user_stats_filtered = pd.read_csv(output_filepath)\n",
    "user_stats_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After moving the data into month subfolders in the study area dir we can pass filter the data for each month by user stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_dirs_months = glob.glob(where.study_area_dir + \"*\")\n",
    "pq_dirs_months_names = [\n",
    "    i.split(f\"{where.study_area_dir}\")[1].split(\".parquet\")[0] for i in pq_dirs_months\n",
    "]\n",
    "uids_pass_qc = list(user_stats_filtered[\"uid\"])\n",
    "data_for_qcd_users = (\n",
    "    f\"{where.study_area_dir}bogota_study_area_{pq_dirs_months_names[0]}_pass_qc.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "\n",
    "for i in tqdm(\n",
    "    range(0, len(pq_dirs_months)), desc=f\"Writing data for users that pass qc\"\n",
    "):\n",
    "    print(f\"Filtering data for {pq_dirs_months_names[i]}...\")\n",
    "    dataset = ds.dataset(pq_dirs_months[i], format=\"parquet\")\n",
    "    table = dataset.to_table(filter=ds.field(\"uid\").isin(uids_pass_qc))\n",
    "    # this causes the kernel to crash when I ran it on all the data so I need to rewrite it to not load everything in memory all at once\n",
    "    data_for_qcd_users = f\"{where.pass_qc_dir}bogota_study_area_{year}_{pq_dirs_months_names[i]}_pass_qc.parquet\"\n",
    "    pq.write_table(table, data_for_qcd_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with different QC thresholds\n",
    "Loads the user stats for the data and produces user stats files filtered with different criteria (e.g. at least 150 or 300 pings) that can later be used to see the impacts of different qc settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = f\"{where.user_stats_dir}user_stats_{year}_allpings_shp_filtered.csv\"\n",
    "user_stats = pd.read_csv(output_filepath)\n",
    "user_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats_filtered = write_filter_user_stats(\n",
    "    user_stats,\n",
    "    output_dir=where.user_stats_dir,\n",
    "    year=year,\n",
    "    filter_by_frequency=True,\n",
    "    min_pings=150,\n",
    "    min_days=min_days,\n",
    ")\n",
    "\n",
    "user_stats_filtered = write_filter_user_stats(\n",
    "    user_stats,\n",
    "    output_dir=where.user_stats_dir,\n",
    "    year=year,\n",
    "    filter_by_frequency=True,\n",
    "    min_pings=300,\n",
    "    min_days=min_days,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_mobile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
