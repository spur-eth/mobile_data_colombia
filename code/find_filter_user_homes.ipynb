{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home and work location mapping \n",
    "The purpose of this notebook is to map the  home and work locations for the users that passed qc. Specifically we want to map: \n",
    "\n",
    "1) All the home locations of users in Bogota \n",
    "2) All the work locations of the users in Bogota\n",
    "3) All the home and work locations of the users that live near the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from plotting import * \n",
    "from preprocess import *\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# Access environment variables and define other necessary variables\n",
    "data_dir = os.getenv('WORKING_DIR')\n",
    "meta_dir = f'{data_dir}metadata/'\n",
    "pq_dir = f'{data_dir}data/parquet/in_study_area/pass_qc/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pings data and map each users' home location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 1. the shapefile with the ZAT and stratum information and 2. the user stats to get the list of users. \n",
    "Note that there are 701961 users that passed qc. Takes quite some time to run (~ 111 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_name_zat = 'zat_stratum'\n",
    "shapefile_zat = f'{meta_dir}income/{shp_name_zat}.shp'\n",
    "regions_gdf_zat = gpd.read_file(shapefile_zat)\n",
    "regions_gdf_zat.plot()\n",
    "\n",
    "user_stats_filepath = f'{data_dir}/data/user_stats/user_stats_2019_months1-8_60min_pings_10min_days_shp_filtered.csv'\n",
    "user_stats_filtered = pd.read_csv(user_stats_filepath)\n",
    "uids_pass_qc= list(user_stats_filtered['uid'])\n",
    "user_stats_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `start_night` and `end_night`, originally choose 22:00 and 6:00 to map home locations. But we can also map daytime hours of course to try to determine work locations for instance and so we did that for 8:00 and 18:00. By defaul the `goal` parameter, which is meant to describe what information you hope to get by finding the location with the most pings within the time window is set `goal='home'`, but for work determination I set `goal=work` for instance, mainly to accurately label the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal='work'\n",
    "start_time = '8:00'\n",
    "end_time = '18:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f'{pq_dir}home_work_locs/{goal}/'\n",
    "cols = ['uid', 'datetime', 'lat', 'lng']\n",
    "gdf_cols = ['Area', 'MUNCod', 'NOMMun', 'ZAT', 'UTAM', 'stratum']\n",
    "\n",
    "compute_home_lat_lngs_for_users(uids_pass_qc=uids_pass_qc, regions_gdf=regions_gdf_zat, pq_dir=pq_dir, \n",
    "                                out_dir=out_dir, num_users=50000, cols = ['uid', 'datetime', 'lat', 'lng'], \n",
    "                                gdf_cols=['Area', 'MUNCod', 'NOMMun', 'ZAT', 'UTAM', 'stratum'],\n",
    "                                start_time=start_time, end_time=end_time, goal=goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the home (or work) locs from all users to find those that live in the zats of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the data for all the users\n",
    "Read in the home (or work) locs files with the home (or work) locations of all the users (lat, lng, ZAT) that we just wrote to get the uids of those users that live/work in those areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f'{pq_dir}home_work_locs/{goal}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_files = glob.glob(out_dir + '*.parquet')\n",
    "all_locs_filepath = f'{out_dir}all_{goal}_locs_0800_1800_w_zats_for_users_pass_qc.csv'\n",
    "hl_df = ds.dataset(locs_files, format=\"parquet\").to_table().to_pandas()\n",
    "hl_df = hl_df.rename(columns={'lat': f'lat_{goal}', 'lng': f'lng_{goal}', 'ZAT': f'ZAT_{goal}', 'UTAM': f'UTAM_{goal}'})\n",
    "hl_df.to_csv(all_locs_filepath)\n",
    "hl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in zats file \n",
    "This file specifies the treatment and control zats. Make sure that the ZATs are the same data type in the `hl_df` and the `zats_tc` dataframes for proper filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "zats_tc_fp = f'{meta_dir}ZAT_treat_control.csv'\n",
    "print(hl_df[f'ZAT_{goal}'].dtypes)\n",
    "zats_tc = pd.read_csv(zats_tc_fp).astype('float64') \n",
    "\n",
    "ztreat = [i for i in list(zats_tc['ZATs Treatment group']) if str(i) != \"nan\"] \n",
    "zcontrol = [i for i in list(zats_tc['ZAT Control group']) if str(i) != \"nan\"] \n",
    "zsel = ztreat + zcontrol\n",
    "zats_tc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the users by the selected zat ids to get the uids of those users that live in those areas\n",
    "Also write out a file with data on the homes and stratum, etc of these users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df_zsel = hl_df[hl_df[f'ZAT_{goal}'].isin(zsel)].copy().reset_index()\n",
    "hl_df_zsel = hl_df_zsel.drop(columns=['index'])\n",
    "\n",
    "zsel_locs_filepath = f'{out_dir}selected_txt_control_{goal}_locs_0800_1800_w_zats_for_users_pass_qc.csv'\n",
    "hl_df_zsel.to_csv(zsel_locs_filepath)\n",
    "hl_df_zsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_locs_in_zsels = list(hl_df_zsel['uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 39,655 users that potentially live in one of the 96 ZATs according to where they have the most pings between 10pm and 6am (which is how skmob calculates home locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the ping data to only include pings from those users that live in the specified ZATs\n",
    "Takes ~2.5 min to filter the data and write all the pq files and 5 min to write the csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_dirs_pass_qc = glob.glob(pq_dir + '*.parquet')\n",
    "pq_dirs_pass_qc_names = [i.split(f'{pq_dir}')[1].split('.parquet')[0] for i in pq_dirs_pass_qc]\n",
    "\n",
    "for i in tqdm(range(0,len(pq_dirs_pass_qc)), desc=f'Writing data for users that pass qc'):\n",
    "    print(f'Filtering data for {pq_dirs_pass_qc_names[i]}...')\n",
    "    dataset = ds.dataset(pq_dirs_pass_qc[i], format=\"parquet\")\n",
    "    table = dataset.to_table(filter=ds.field('uid').isin(users_locs_in_zsels))\n",
    "    data_for_users_in_zats = f'{pq_dir}/in_zats/{goal}_in_zats/{pq_dirs_pass_qc_names[i]}_selected_zats_{goal}.parquet'\n",
    "    pq.write_table(table, data_for_users_in_zats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a parquet and csv file for the pings for all the users in the ZATs\n",
    "Time: ~1 minute for the parquet file and ~5 minutes for the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_zats_dir = f'{pq_dir}/in_zats/{goal}_in_zats/'\n",
    "in_zats_dir_pq = glob.glob(in_zats_dir + f'*{goal}.parquet')\n",
    "print(in_zats_dir_pq)\n",
    "in_zats_pings_df = ds.dataset(in_zats_dir_pq, format=\"parquet\").to_table().to_pandas().reset_index()\n",
    "in_zats_pings_df = in_zats_pings_df.drop(columns=['index'])\n",
    "in_zats_pings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_zats_pings_df_filepath = f'{in_zats_dir}pings_{goal}_locs_0800_1800_w_zats_for_users_pass_qc_living_in_selzats.csv'\n",
    "in_zats_pings_df.to_csv(in_zats_pings_df_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_mobile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
