{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home and work location mapping \n",
    "The purpose of this notebook is to map the  home and work locations for the users that passed qc. Specifically we want to map: \n",
    "\n",
    "1) All the home locations of users in Bogota \n",
    "2) All the work locations of the users in Bogota\n",
    "3) All the home and work locations of the users that live near the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from plotting import * \n",
    "from preprocess import *\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# Access environment variables and define other necessary variables\n",
    "data_dir = os.getenv('WORKING_DIR')\n",
    "meta_dir = f'{data_dir}metadata/'\n",
    "pq_dir = f'{data_dir}data/parquet/in_study_area/pass_qc/'\n",
    "out_dir_hw = f'{data_dir}data/home_work/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pings data and map each users' home location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 1. the shapefile with the ZAT and stratum information and 2. the user stats to get the list of users. \n",
    "Note that there are 701961 users that passed qc. Takes quite some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_name_zat = 'zat_stratum'\n",
    "shapefile_zat = f'{meta_dir}income/{shp_name_zat}.shp'\n",
    "regions_gdf_zat = gpd.read_file(shapefile_zat)\n",
    "regions_gdf_zat.plot()\n",
    "\n",
    "output_filepath = f'{data_dir}/data/user_stats/user_stats_2019_months1-8_60min_pings_10min_days_shp_filtered.csv'\n",
    "user_stats_filtered = pd.read_csv(output_filepath)\n",
    "uids_pass_qc= list(user_stats_filtered['uid'])\n",
    "user_stats_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f'{pq_dir}home_locs/'\n",
    "cols = ['uid', 'datetime', 'lat', 'lng']\n",
    "gdf_cols = ['Area', 'MUNCod', 'NOMMun', 'ZAT', 'UTAM', 'stratum']\n",
    "\n",
    "compute_home_lat_lngs_for_users(uids_pass_qc=uids_pass_qc, regions_gdf=regions_gdf_zat, pq_dir=pq_dir, \n",
    "                                out_dir=out_dir, num_users=50000, cols = ['uid', 'datetime', 'lat', 'lng'], \n",
    "                                gdf_cols=['Area', 'MUNCod', 'NOMMun', 'ZAT', 'UTAM', 'stratum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the home locs from all users to find those that live in the zats of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the data for all the users\n",
    "Read in the home locs files with the home locations of all the users (lat, lng, ZAT) that we just wrote to get the uids of those users that live in those areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locs_files = glob.glob(out_dir + '*.parquet')\n",
    "all_home_locs_filepath = f'{out_dir}all_home_locs_2200_0600_w_zats_for_users_pass_qc.csv'\n",
    "hl_df = ds.dataset(home_locs_files, format=\"parquet\").to_table().to_pandas()\n",
    "hl_df = hl_df.rename(columns={'lat': 'lat_home', 'lng': 'lng_home', 'ZAT': 'ZAT_home', 'UTAM': 'UTAM_home'})\n",
    "hl_df.to_csv(all_home_locs_filepath)\n",
    "hl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in zats file \n",
    "This file specifies the treatment and control zats. Make sure that the ZATs are the same data type in the `hl_df` and the `zats_tc` dataframes for proper filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "zats_tc_fp = f'{meta_dir}ZAT_treat_control.csv'\n",
    "print(hl_df.ZAT_home.dtypes)\n",
    "zats_tc = pd.read_csv(zats_tc_fp).astype('float64') \n",
    "\n",
    "ztreat = [i for i in list(zats_tc['ZATs Treatment group']) if str(i) != \"nan\"] \n",
    "zcontrol = [i for i in list(zats_tc['ZAT Control group']) if str(i) != \"nan\"] \n",
    "zsel = ztreat + zcontrol\n",
    "zats_tc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the users by the selected zat ids to get the uids of those users that live in those areas\n",
    "Also write out a file with data on the homes and stratum, etc of these users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df_zsel = hl_df[hl_df['ZAT_home'].isin(zsel)].copy().reset_index()\n",
    "hl_df_zsel = hl_df_zsel.drop(columns=['index'])\n",
    "\n",
    "zsel_home_locs_filepath = f'{out_dir}selected_txt_control_home_locs_2200_0600_w_zats_for_users_pass_qc.csv'\n",
    "hl_df_zsel.to_csv(zsel_home_locs_filepath)\n",
    "hl_df_zsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_living_in_zsels = list(hl_df_zsel['uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 39,655 users that potentially live in one of the 96 ZATs according to where they have the most pings between 10pm and 6am (which is how skmob calculates home locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the ping data to only include pings from those users that live in the specified ZATs\n",
    "Takes ~2.5 min to filter the data and write all the pq files and 5 min to write the csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_dirs_pass_qc = glob.glob(pq_dir + '*.parquet')\n",
    "pq_dirs_pass_qc_names = [i.split(f'{pq_dir}')[1].split('.parquet')[0] for i in pq_dirs_pass_qc]\n",
    "\n",
    "for i in tqdm(range(0,len(pq_dirs_pass_qc)), desc=f'Writing data for users that pass qc'):\n",
    "    print(f'Filtering data for {pq_dirs_pass_qc_names[i]}...')\n",
    "    dataset = ds.dataset(pq_dirs_pass_qc[i], format=\"parquet\")\n",
    "    table = dataset.to_table(filter=ds.field('uid').isin(users_living_in_zsels))\n",
    "    data_for_users_in_zats = f'{pq_dir}/in_zats/{pq_dirs_pass_qc_names[i]}_selected_zats.parquet'\n",
    "    pq.write_table(table, data_for_users_in_zats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a csv file for the pings for all the users in the ZATs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_zats_dir = f'{pq_dir}/in_zats/'\n",
    "in_zats_dir_pq = glob.glob(in_zats_dir + '*.parquet')\n",
    "in_zats_pings_df = ds.dataset(in_zats_dir_pq, format=\"parquet\").to_table().to_pandas().reset_index()\n",
    "in_zats_pings_df = in_zats_pings_df.drop(columns=['index'])\n",
    "in_zats_pings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_zats_pings_df_filepath = f'{in_zats_dir}pings_home_locs_2200_0600_w_zats_for_users_pass_qc_living_in_selzats.csv'\n",
    "in_zats_pings_df.to_csv(in_zats_pings_df_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_mobile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
